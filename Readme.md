<p align="center">
   <h1>DiffRhythm: Blazingly Fast and Embarrassingly Simple</br>End-to-End Full-Length Song Generation with Latent Diffusion</h1>
</p>

Ziqian Ning, Huakang Chen, Yuepeng Jiang, Chunbo Hao, Guobin Ma, Shuai Wang, Jixun Yao, Lei Xieâ€ 

<p align="center">
 <a href="https://huggingface.co/spaces/ASLP-lab/DiffRhythm"> Huggingface Space Demo</a> </a>&nbsp
<br>
ðŸ“‘ <a href="https://arxiv.org/abs/2503.01183">Paper</a> &nbsp&nbsp | &nbsp&nbsp ðŸ“‘ <a href="https://aslp-lab.github.io/DiffRhythm.github.io/">Demo</a> &nbsp&nbsp | &nbsp&nbsp ðŸ’¬ <a href="images/introduction.md">WeChat (å¾®ä¿¡)</a>&nbsp&nbsp 
</p>

DiffRhythm (Chinese: è°›éŸµ, DÃ¬ YÃ¹n) is the ***first*** diffusion-based song generation model that is capable of creating full-length songs. The name combines "Diff" (referencing its diffusion architecture) with "Rhythm" (highlighting its focus on music and song creation). The Chinese name è°›éŸµ (DÃ¬ YÃ¹n) phonetically mirrors "DiffRhythm", where "è°›" (attentive listening) symbolizes auditory perception, and "éŸµ" (melodic charm) represents musicality.


<p align="center">
    <img src="src/diffrhythm.jpg" width="90%"/>
<p>

## News and Updates

### 2025.3.4 ðŸ”¥ We released the [DiffRhythm paper](https://arxiv.org/abs/2503.01183) and [Huggingface Space demo](https://huggingface.co/spaces/ASLP-lab/DiffRhythm).

## TODOs
- [ ] Support local deployment:
- [ ] Support Colab:
- [ ] Support Docker:
- [x] Release paper to Arxiv.
- [x] Online serving on huggingface space.

## Model Versions

|  Model   | HuggingFace |
|  ----  | ----  |
| DiffRhythm-base (1m35s)  | https://huggingface.co/ASLP-lab/DiffRhythm-base |
| DiffRhythm-full (4m45s)  | Coming soon... |
| DiffRhythm-vae  | https://huggingface.co/ASLP-lab/DiffRhythm-vae |


## License & Disclaimer

As the VAE is fine-tuned from [Stable Audio Open](https://huggingface.co/stabilityai/stable-audio-open-1.0), DiffRhythm is subject to the [Stability AI Community License Agreement](LICENSE.md)

DiffRhythm enables the creation of original music across diverse genres, supporting applications in artistic creation, education, and entertainment. While designed for positive use cases, potential risks include unintentional copyright infringement through stylistic similarities, inappropriate blending of cultural musical elements, and misuse for generating harmful content. To ensure responsible deployment, users must implement verification mechanisms to confirm musical originality, disclose AI involvement in generated works, and obtain permissions when adapting protected styles.

## Citation
```
@article{ning2025diffrhythm,
  title={{DiffRhythm}: Blazingly Fast and Embarrassingly Simple</br>End-to-End Full-Length Song Generation with Latent Diffusion<},
  author={Geng, Xuelong and Wei, Kun and Shao, Qijie and Liu, Shuiyun and Lin, Zhennan and Zhao, Zhixian and Li, Guojian and Tian, Wenjie and Chen, Peikun and Li, Yangze and others
  Ziqian, Ning and Huakang, Chen and Yuepeng, Jiang and Chunbo, Hao and Guobin, Ma and Shuai, Wang and Jixun, Yao and Lei, Xie},
  journal={arXiv preprint arXiv:2503.01183},
  year={2025}
}
```
## Contact Us

If you are interested in leaving a message to our research team, feel free to email `nzqiann@gmail.com`.
<p align="center">
    <a href="http://www.nwpu-aslp.org/">
        <img src="src/ASLP.jpg" width="400"/>
    </a>
</p>